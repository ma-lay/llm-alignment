# llm-alignment
Systematic Evaluation and Mitigation of Alignment Failures in Large Language Models Under Adversarial Prompting
